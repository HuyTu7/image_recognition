{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from PIL import Image, ImageFilter\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deskew(img):\n",
    "    m = cv2.moments(img)\n",
    "    SZ=40\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        # no deskewing needed. \n",
    "        return img.copy()\n",
    "    # Calculate skew based on central momemts. \n",
    "    skew = m['mu11']/m['mu02']\n",
    "    # Calculate affine transform to correct skewness. \n",
    "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "    # Apply affine transform\n",
    "    img = cv2.warpAffine(img, M, (SZ, SZ), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_image(img):\n",
    "    s = img.shape[0] * img.shape[1]\n",
    "    img_wide = img.reshape(1, s)\n",
    "    return img_wide[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structures = [x for x in os.walk('../Caltech10/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_operating(fname, item):\n",
    "    # save or load the pickle file.\n",
    "    file_name = '%s.pickle' % fname\n",
    "    print(file_name)\n",
    "    if not item:\n",
    "        with open(file_name, 'rb') as fs:\n",
    "            item = pickle.load(fs)\n",
    "            return item\n",
    "    else:\n",
    "        with open(file_name, 'wb') as fs:\n",
    "            pickle.dump(item, fs, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_imgs(folders):\n",
    "    dataset = {'categories': {}, 'data': {}}\n",
    "    data = []\n",
    "    label = 0\n",
    "    size = (128, 128)\n",
    "    for f in folders:\n",
    "        dataset['categories'][f[0]] = label\n",
    "        dataset['data'][label] = []\n",
    "        for i in f[2]:\n",
    "            image = Image.open(\"%s/%s\"%(f[0], i)).resize(size)\n",
    "            img = image.convert(\"L\").filter(ImageFilter.GaussianBlur(radius = 2))\n",
    "            im_data = list(img.getdata())\n",
    "            dataset['data'][label].append((im_data, label))\n",
    "        label += 1\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.pickle\n",
      "dataset.pickle\n"
     ]
    }
   ],
   "source": [
    "dataset = save_imgs(structures)\n",
    "pickle_operating('dataset', dataset)\n",
    "dataset_1 = pickle_operating('dataset', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_splitting(size, data):\n",
    "    train_data, test_data = [], []\n",
    "    for i in data.keys():\n",
    "        x = range(len(data[i]))\n",
    "        shuffle(x)\n",
    "        train_size = int(size*len(data[i]))\n",
    "        train_indexes, test_indexes = x[:train_size], x[train_size:]\n",
    "        train_data.extend(np.array(data[i])[train_indexes]) \n",
    "        test_data.extend(np.array(data[i])[test_indexes])\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_1.pickle\n"
     ]
    }
   ],
   "source": [
    "dataset['experiment'] = {}\n",
    "dataset['experiment']['train'], dataset['experiment']['test'] = train_test_splitting(0.5, dataset_1['data'])\n",
    "pickle_operating('dataset_1', dataset['experiment'])\n",
    "scipy.io.savemat('myexpdata.mat', \n",
    "                 mdict={'train': dataset['experiment']['train'], \n",
    "                        'test': dataset['experiment']['test']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "print(dataset['experiment']['train'], dataset['experiment']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
