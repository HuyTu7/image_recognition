{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import statistics \n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def pickle_operating(fname, item):\n",
    "    # save or load the pickle file.\n",
    "    file_name = '%s.pickle' % fname\n",
    "    print(file_name)\n",
    "    if not item:\n",
    "        with open(file_name, 'rb') as fs:\n",
    "            item = pickle.load(fs)\n",
    "            return item\n",
    "    else:\n",
    "        with open(file_name, 'wb') as fs:\n",
    "            pickle.dump(item, fs, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the node of the decision tree\n",
    "class decision_node:\n",
    "    def __init__(self, feature=-1, val=None, results=None, rb=None, lb=None):\n",
    "        self.feature = feature \n",
    "        self.value = val\n",
    "        self.results = results \n",
    "        self.leftb = lb \n",
    "        self.rightb = rb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the data based on the value of the specific column\n",
    "def sets_split(data, column, value):\n",
    "    split_function = lambda row:row[column] >= value\n",
    "    set1, set2 = [[], []], [[], []]\n",
    "    for i in range(len(data[0])): \n",
    "        if split_function(data[0][i]):\n",
    "            set1[0].append(data[0][i])\n",
    "            set1[1].append(data[1][i])\n",
    "        else:\n",
    "            set2[0].append(data[0][i])\n",
    "            set2[1].append(data[1][i])\n",
    "    return [set1, set2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the entropy from the data source\n",
    "def entropy(data, labels):\n",
    "    results_freq = {}\n",
    "    ent = 0.0\n",
    "    for i in range(len(data)):\n",
    "        if labels[i] in results_freq.keys():\n",
    "            results_freq[labels[i]] += 1\n",
    "        else:\n",
    "            results_freq[labels[i]] = 1\n",
    "    \n",
    "    for label, freq in results_freq.items():\n",
    "        ent -= float(freq)/len(data) * math.log(float(freq)/len(data), 2) \n",
    "    return ent\n",
    "\n",
    "\n",
    "#information gaining from this splitting\n",
    "def info_gain(set1, set2, data_length, current_score):\n",
    "    p = float(len(set1)) / data_length\n",
    "    info = current_score - p*entropy(set1[0], set1[1]) - (1-p)*entropy(set2[0], set2[1])\n",
    "    return info\n",
    "\n",
    "\n",
    "#make decision on the label/category of the data\n",
    "def to_decide(records):\n",
    "    res = {}\n",
    "    for record in records:\n",
    "        if record in res:\n",
    "            res[record] += 1\n",
    "        else:\n",
    "            res[record] = 1\n",
    "    sorted_labels = sorted(res.iteritems(), key=itemgetter(1), reverse=True)\n",
    "    return sorted_labels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting the data based on all of the columns \n",
    "#and find the best splitting\n",
    "def get_best_split(data, split_decision='median'):\n",
    "    column_count = len(data[0][0])\n",
    "    \n",
    "    current_score = entropy(data[0], data[1])\n",
    "    data_length = len(data[0])\n",
    "    best = {'score': 0, 'criteria': None, 'sets': None}\n",
    "    for col in range(0, column_count):\n",
    "        column_values = [row[col] for row in data[0]]\n",
    "        if split_decision == 'median':\n",
    "            value = np.median(column_values)\n",
    "        else:\n",
    "            value = np.mean(column_values)\n",
    "        set1, set2 = sets_split(data, col, value)\n",
    "        info = info_gain(set1, set2, data_length, current_score)\n",
    "        if info > best['score'] and len(set1) > 0 and len(set2) > 0:\n",
    "            best['score'], best['feature'], best['sets'] = info, (col, value), (set1, set2)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grow the decision tree recursively\n",
    "def grow_tree(data, level, max_level=5, split_method='median'):\n",
    "    if len(data[0]) == 0: \n",
    "        return \n",
    "    if level >= max_level:\n",
    "        return decision_node(results=to_decide(data[1]))\n",
    "    best = get_best_split(data, split_method)\n",
    "    if best['score'] > 0:\n",
    "        right_branch = grow_tree(best['sets'][0], level+1, max_level) \n",
    "        left_branch = grow_tree(best['sets'][1], level+1, max_level)\n",
    "        return decision_node(feature=best['feature'][0], val=best['feature'][1],\n",
    "                             rb=right_branch, lb=left_branch)\n",
    "    else:\n",
    "        return decision_node(results=to_decide(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recursive going down the tree to classify the new data point\n",
    "def predict(node, row):\n",
    "    if row[node.feature] < node.value:\n",
    "        if node.leftb.results != None:\n",
    "            return node.leftb.results\n",
    "        else:\n",
    "            return predict(node.leftb, row)\n",
    "    else:\n",
    "        if node.rightb.results != None:\n",
    "            return node.rightb.results\n",
    "        else:\n",
    "            return predict(node.rightb, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build the tree on the train data\n",
    "def experiment(train_data, depth, split_method):\n",
    "    x_train, y_train  = [x[0] for x in train_data], [x[1] for x in train_data]\n",
    "    tree = grow_tree([x_train, y_train], 0, depth, split_method)\n",
    "    pickle_operating('dt_model', tree)\n",
    "    print(\"finished growing the tree!\")\n",
    "    return tree\n",
    "\n",
    "#predicting the test data based on the tree model\n",
    "#and evaluated the predictions\n",
    "def predicting(tree, test_data):\n",
    "    x_test, y_test  = [x[0] for x in test_data], [x[1] for x in test_data]\n",
    "    predictions = []\n",
    "    for row in x_test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech_data_3.pickle\n",
      "(320, 324)\n"
     ]
    }
   ],
   "source": [
    "#experimentation runs for Caltech Data after PCA\n",
    "dataset = pickle_operating('Caltech_data_3', None)\n",
    "print(len(dataset['train']), len(dataset['test']))\n",
    "shuffle(dataset['train'])\n",
    "shuffle(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_model.pickle\n",
      "finished growing the tree!\n"
     ]
    }
   ],
   "source": [
    "tree_model = experiment(dataset['train'], 5, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.21      0.31      0.25        36\n",
      "          2       0.16      0.23      0.19        31\n",
      "          3       0.71      0.45      0.56        33\n",
      "          4       0.25      0.05      0.08        21\n",
      "          5       0.34      0.44      0.38        43\n",
      "          6       0.28      0.39      0.33        46\n",
      "          7       0.21      0.16      0.18        32\n",
      "          8       0.11      0.11      0.11        27\n",
      "          9       0.27      0.16      0.20        25\n",
      "         10       0.81      0.43      0.57        30\n",
      "\n",
      "avg / total       0.34      0.30      0.30       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predicting(tree_model, dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data_2.pickle\n",
      "(60000, 10000)\n"
     ]
    }
   ],
   "source": [
    "#experimentation runs for MNIST Data after PCA\n",
    "dataset = pickle_operating('MNIST_data_2', None)\n",
    "print(len(dataset['train']), len(dataset['test']))\n",
    "#randomized the data to avoid the biases\n",
    "shuffle(dataset['train'])\n",
    "shuffle(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_model.pickle\n",
      "finished growing the tree!\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86       980\n",
      "          1       0.95      0.95      0.95      1135\n",
      "          2       0.78      0.78      0.78      1032\n",
      "          3       0.75      0.74      0.74      1010\n",
      "          4       0.73      0.68      0.70       982\n",
      "          5       0.77      0.70      0.73       892\n",
      "          6       0.91      0.86      0.88       958\n",
      "          7       0.83      0.74      0.78      1028\n",
      "          8       0.66      0.75      0.70       974\n",
      "          9       0.65      0.70      0.67      1009\n",
      "\n",
      "avg / total       0.79      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_model = experiment(dataset['train'], 15, 'median')\n",
    "predictions = predicting(tree_model, dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
