{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import statistics\n",
    "import random\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def pickle_operating(fname, item):\n",
    "    # save or load the pickle file.\n",
    "    file_name = '%s.pickle' % fname\n",
    "    print(file_name)\n",
    "    if not item:\n",
    "        with open(file_name, 'rb') as fs:\n",
    "            item = pickle.load(fs)\n",
    "            return item\n",
    "    else:\n",
    "        with open(file_name, 'wb') as fs:\n",
    "            pickle.dump(item, fs, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the node of the decision tree\n",
    "class decision_node:\n",
    "    def __init__(self, feature=-1, val=None, results=None, rb=None, lb=None):\n",
    "        self.feature = feature \n",
    "        self.value = val\n",
    "        self.results = results \n",
    "        self.leftb = lb \n",
    "        self.rightb = rb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the data based on the value of the specific column\n",
    "def sets_split(data, column, value):\n",
    "    split_function = lambda row:row[column] >= value\n",
    "    set1, set2 = [[], []], [[], []]\n",
    "    for i in range(len(data[0])): \n",
    "        if split_function(data[0][i]):\n",
    "            set1[0].append(data[0][i])\n",
    "            set1[1].append(data[1][i])\n",
    "        else:\n",
    "            set2[0].append(data[0][i])\n",
    "            set2[1].append(data[1][i])\n",
    "    return [set1, set2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the entropy from the data source\n",
    "def entropy(data, labels):\n",
    "    results_freq = {}\n",
    "    ent = 0.0\n",
    "    for i in range(len(data)):\n",
    "        if labels[i] in results_freq.keys():\n",
    "            results_freq[labels[i]] += 1\n",
    "        else:\n",
    "            results_freq[labels[i]] = 1\n",
    "    \n",
    "    for label, freq in results_freq.items():\n",
    "        ent -= float(freq)/len(data) * math.log(float(freq)/len(data), 2) \n",
    "    return ent\n",
    "\n",
    "\n",
    "#information gaining from this splitting\n",
    "def info_gain(set1, set2, data_length, current_score):\n",
    "    p = float(len(set1)) / data_length\n",
    "    info = current_score - p*entropy(set1[0], set1[1]) - (1-p)*entropy(set2[0], set2[1])\n",
    "    return info\n",
    "\n",
    "\n",
    "#make decision on the label/category of the data\n",
    "def to_decide(records, labels):\n",
    "    res = {}\n",
    "    for record in records:\n",
    "        if record in res:\n",
    "            res[record] += 1\n",
    "        else:\n",
    "            res[record] = 1\n",
    "    sorted_labels = sorted(res.iteritems(), key=itemgetter(1), reverse=True)\n",
    "    if sorted_labels:\n",
    "        return sorted_labels[0][0]\n",
    "    else:\n",
    "        return random.choice(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def gini_scoring(labels, size, categories):\n",
    "    score = 0.0\n",
    "    for cat in categories:\n",
    "        p = labels.count(cat) / size\n",
    "        score += p * p\n",
    "    return score\n",
    "\n",
    "def gini_index(set1, set2, data_length, categories):\n",
    "    n_instances = data_length\n",
    "    gini = 0.0\n",
    "    #cats = set(labels)\n",
    "    for sample in [set1, set2]:\n",
    "        size = float(len(sample[0]))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        #print(len(sample[1]))\n",
    "        score = gini_scoring(sample[1], size, categories)\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "        #print(gini)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitting_value(column_values, split_decision):\n",
    "    if split_decision == 'median':\n",
    "        return np.median(column_values)\n",
    "    else:\n",
    "        return np.mean(column_values)\n",
    "\n",
    "def scoring_methods(data, method, labels, data_length, current_score):\n",
    "    if method == \"entropy\":\n",
    "        score = info_gain(data[0], data[1], data_length, current_score)\n",
    "    else:\n",
    "        score = gini_index(data[0], data[1], data_length, labels)\n",
    "    return score\n",
    "\n",
    "def score_comparison(method, score1, score2=-1, split=False):\n",
    "    if split:\n",
    "        if method == \"entropy\":\n",
    "            return score1 > score2\n",
    "        else:\n",
    "            return score1 < score2\n",
    "    else:\n",
    "        if method == \"entropy\":\n",
    "            return score1 > 0\n",
    "        else:\n",
    "            return score1 < 1\n",
    "\n",
    "#splitting the data based on all of the columns \n",
    "#and find the best splitting\n",
    "def get_best_split(data, score_method=\"entropy\", split_decision='median'):\n",
    "    column_count = len(data[0][0])\n",
    "    labels = set(data[1])\n",
    "    current_score = entropy(data[0], data[1])\n",
    "    data_length = len(data[0])\n",
    "    if score_method==\"entropy\":\n",
    "        best = {'score': 0.0, 'feature': None, 'sets': [[[], []], [[], []]]}\n",
    "    else:\n",
    "        best = {'score': 2.0, 'feature': None, 'sets': [[[], []], [[], []]]}\n",
    "    for col in range(0, column_count):\n",
    "        column_values = [row[col] for row in data[0]]\n",
    "        value = splitting_value(column_values, split_decision)\n",
    "        set1, set2 = sets_split(data, col, value)\n",
    "        info = scoring_methods([set1, set2], score_method, labels, data_length, current_score)\n",
    "        best_flag = score_comparison(score_method, info, best['score'], True)\n",
    "        if best_flag and len(set1) > 0 and len(set2) > 0:\n",
    "            best['score'], best['feature'], best['sets'] = info, (col, value), (set1, set2)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_tree(data, min_size=10, labels=[], level=0, max_level=5, score_method=\"entropy\", split_method='median'):\n",
    "    if len(data[0]) < min_size:\n",
    "        return decision_node(results=to_decide(data[1], labels))\n",
    "        #return decision_node(results=random.choice(labels))\n",
    "    if level >= max_level:\n",
    "        return decision_node(results=to_decide(data[1], labels))\n",
    "    best = get_best_split(data, score_method, split_method)\n",
    "    best_flag = score_comparison(score_method, best['score'])\n",
    "    if best_flag:\n",
    "        if not best['feature']:\n",
    "            print(best['score'], level)\n",
    "        right_branch = grow_tree(best['sets'][0], min_size, labels, level+1, max_level, score_method, split_method) \n",
    "        left_branch = grow_tree(best['sets'][1], min_size, labels, level+1, max_level, score_method, split_method)\n",
    "        return decision_node(feature=best['feature'][0], val=best['feature'][1],\n",
    "                             rb=right_branch, lb=left_branch)\n",
    "    else:\n",
    "        return decision_node(results=to_decide(data[1], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recursive going down the tree to classify the new data point\n",
    "def predict(node, row):\n",
    "    if row[node.feature] < node.value:\n",
    "        if node.leftb.results != None:\n",
    "            return node.leftb.results\n",
    "        else:\n",
    "            return predict(node.leftb, row)\n",
    "    else:\n",
    "        if node.rightb.results != None:\n",
    "            return node.rightb.results\n",
    "        else:\n",
    "            return predict(node.rightb, row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree, indent=''):\n",
    "    if tree:\n",
    "        if tree.results:\n",
    "            print str(tree.results)\n",
    "        else:\n",
    "            # Print the criteria\n",
    "            print 'Column ' + str(tree.feature)+' : '+str(tree.value)+'? '\n",
    "\n",
    "            # Print the branches\n",
    "            string = indent + 'Larger->'\n",
    "            print string, \n",
    "            print_tree(tree.rightb, indent + '  ')\n",
    "            string = indent+'Smaller->'\n",
    "            print string,\n",
    "            print_tree(tree.leftb, indent + '  ')\n",
    "    else:\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build the tree on the train data\n",
    "def experiment(train_data, min_size, depth, score_method, split_method):\n",
    "    x_train, y_train  = [x[0] for x in train_data], [x[1] for x in train_data]\n",
    "    labels = list(set(y_train))\n",
    "    tree = grow_tree([x_train, y_train], min_size, labels, 0, depth, score_method, split_method)\n",
    "    pickle_operating('dt_model', tree)\n",
    "    print(\"finished growing the tree!\")\n",
    "    return tree\n",
    "\n",
    "#predicting the test data based on the tree model\n",
    "#and evaluated the predictions\n",
    "def predicting(tree, test_data):\n",
    "    x_test, y_test  = [x[0] for x in test_data], [x[1] for x in test_data]\n",
    "    predictions = []\n",
    "    for row in x_test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech_data_2.pickle\n",
      "(320, 324)\n"
     ]
    }
   ],
   "source": [
    "#experimentation runs for Caltech Data after PCA\n",
    "dataset = pickle_operating('Caltech_data_2', None)\n",
    "print(len(dataset['train']), len(dataset['test']))\n",
    "shuffle(dataset['train'])\n",
    "shuffle(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_model.pickle\n",
      "finished growing the tree!\n"
     ]
    }
   ],
   "source": [
    "tree_model_entropy = experiment(dataset['train'], 15, 10, 'entropy', 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.17      0.11      0.13        36\n",
      "          2       0.10      0.06      0.08        31\n",
      "          3       0.26      0.45      0.33        33\n",
      "          4       0.22      0.10      0.13        21\n",
      "          5       0.45      0.35      0.39        43\n",
      "          6       0.25      0.20      0.22        46\n",
      "          7       0.12      0.12      0.12        32\n",
      "          8       0.17      0.22      0.19        27\n",
      "          9       0.18      0.16      0.17        25\n",
      "         10       0.25      0.43      0.32        30\n",
      "\n",
      "avg / total       0.23      0.23      0.22       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predicting(tree_model_entropy, dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_model.pickle\n",
      "finished growing the tree!\n"
     ]
    }
   ],
   "source": [
    "tree_model_gini = experiment(dataset['train'], 15, 10, 'gini', 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.19      0.25      0.22        36\n",
      "          2       0.21      0.16      0.18        31\n",
      "          3       0.31      0.45      0.37        33\n",
      "          4       0.09      0.14      0.11        21\n",
      "          5       0.47      0.37      0.42        43\n",
      "          6       0.16      0.17      0.17        46\n",
      "          7       0.21      0.12      0.16        32\n",
      "          8       0.05      0.04      0.04        27\n",
      "          9       0.31      0.36      0.33        25\n",
      "         10       0.84      0.53      0.65        30\n",
      "\n",
      "avg / total       0.29      0.27      0.27       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predicting(tree_model_gini, dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data_2.pickle\n",
      "(60000, 10000)\n"
     ]
    }
   ],
   "source": [
    "#experimentation runs for MNIST Data after PCA\n",
    "dataset = pickle_operating('MNIST_data_2', None)\n",
    "print(len(dataset['train']), len(dataset['test']))\n",
    "#randomized the data to avoid the biases\n",
    "shuffle(dataset['train'])\n",
    "shuffle(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_model.pickle\n",
      "finished growing the tree!\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.86      0.84       980\n",
      "          1       0.95      0.95      0.95      1135\n",
      "          2       0.82      0.82      0.82      1032\n",
      "          3       0.76      0.80      0.78      1010\n",
      "          4       0.70      0.69      0.70       982\n",
      "          5       0.73      0.67      0.70       892\n",
      "          6       0.87      0.87      0.87       958\n",
      "          7       0.85      0.79      0.82      1028\n",
      "          8       0.73      0.74      0.73       974\n",
      "          9       0.68      0.71      0.70      1009\n",
      "\n",
      "avg / total       0.79      0.79      0.79     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_model_gini = experiment(dataset['train'], 15, 10, 'gini', 'median')\n",
    "predictions = predicting(tree_model_gini, dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_model.pickle\n",
      "finished growing the tree!\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.87      0.84       980\n",
      "          1       0.96      0.94      0.95      1135\n",
      "          2       0.75      0.78      0.76      1032\n",
      "          3       0.73      0.81      0.77      1010\n",
      "          4       0.71      0.69      0.70       982\n",
      "          5       0.77      0.68      0.72       892\n",
      "          6       0.87      0.88      0.87       958\n",
      "          7       0.75      0.77      0.76      1028\n",
      "          8       0.74      0.71      0.73       974\n",
      "          9       0.69      0.65      0.67      1009\n",
      "\n",
      "avg / total       0.78      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_model_entropy = experiment(dataset['train'], 20, 15, 'entropy', 'median')\n",
    "predictions = predicting(tree_model_entropy, dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
